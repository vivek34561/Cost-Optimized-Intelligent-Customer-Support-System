{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48bf57bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"hf://datasets/bitext/Bitext-customer-support-llm-chatbot-training-dataset/Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "539b0af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flags</th>\n",
       "      <th>instruction</th>\n",
       "      <th>category</th>\n",
       "      <th>intent</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>question about cancelling order {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I've understood you have a question regarding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BQZ</td>\n",
       "      <td>i have a question about cancelling oorder {{Or...</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I've been informed that you have a question ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLQZ</td>\n",
       "      <td>i need help cancelling puchase {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I can sense that you're seeking assistance wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BL</td>\n",
       "      <td>I need to cancel purchase {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I understood that you need assistance with can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCELN</td>\n",
       "      <td>I cannot afford this order, cancel purchase {{...</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I'm sensitive to the fact that you're facing f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flags                                        instruction category  \\\n",
       "0      B   question about cancelling order {{Order Number}}    ORDER   \n",
       "1    BQZ  i have a question about cancelling oorder {{Or...    ORDER   \n",
       "2   BLQZ    i need help cancelling puchase {{Order Number}}    ORDER   \n",
       "3     BL         I need to cancel purchase {{Order Number}}    ORDER   \n",
       "4  BCELN  I cannot afford this order, cancel purchase {{...    ORDER   \n",
       "\n",
       "         intent                                           response  \n",
       "0  cancel_order  I've understood you have a question regarding ...  \n",
       "1  cancel_order  I've been informed that you have a question ab...  \n",
       "2  cancel_order  I can sense that you're seeking assistance wit...  \n",
       "3  cancel_order  I understood that you need assistance with can...  \n",
       "4  cancel_order  I'm sensitive to the fact that you're facing f...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84a7a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (26872, 5)\n",
      "\n",
      "Column names: ['flags', 'instruction', 'category', 'intent', 'response']\n",
      "\n",
      "Data types:\n",
      "flags          str\n",
      "instruction    str\n",
      "category       str\n",
      "intent         str\n",
      "response       str\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "flags          0\n",
      "instruction    0\n",
      "category       0\n",
      "intent         0\n",
      "response       0\n",
      "dtype: int64\n",
      "\n",
      "Number of unique intents: 27\n",
      "\n",
      "Intent distribution:\n",
      "intent\n",
      "check_invoice               1000\n",
      "complaint                   1000\n",
      "contact_customer_service    1000\n",
      "edit_account                1000\n",
      "switch_account              1000\n",
      "check_payment_methods        999\n",
      "contact_human_agent          999\n",
      "delivery_period              999\n",
      "get_invoice                  999\n",
      "newsletter_subscription      999\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check dataset info\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nColumn names:\", df.columns.tolist())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nNumber of unique intents:\", df['intent'].nunique())\n",
    "print(\"\\nIntent distribution:\")\n",
    "print(df['intent'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997b3ce9",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3b87a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after cleaning: (26872, 6)\n",
      "\n",
      "Sample cleaned instructions:\n",
      "                                         instruction  \\\n",
      "0   question about cancelling order {{Order Number}}   \n",
      "1  i have a question about cancelling oorder {{Or...   \n",
      "2    i need help cancelling puchase {{Order Number}}   \n",
      "3         I need to cancel purchase {{Order Number}}   \n",
      "4  I cannot afford this order, cancel purchase {{...   \n",
      "5     can you help me cancel order {{Order Number}}?   \n",
      "6  I can no longer afford order {{Order Number}},...   \n",
      "7    I am trying to cancel purchase {{Order Number}}   \n",
      "8     I have got to cancel purchase {{Order Number}}   \n",
      "9    i need help canceling purchase {{Order Number}}   \n",
      "\n",
      "                             instruction_clean        intent  \n",
      "0              question about cancelling order  cancel_order  \n",
      "1    i have a question about cancelling oorder  cancel_order  \n",
      "2               i need help cancelling puchase  cancel_order  \n",
      "3                    i need to cancel purchase  cancel_order  \n",
      "4  i cannot afford this order, cancel purchase  cancel_order  \n",
      "5               can you help me cancel order ?  cancel_order  \n",
      "6     i can no longer afford order , cancel it  cancel_order  \n",
      "7               i am trying to cancel purchase  cancel_order  \n",
      "8                i have got to cancel purchase  cancel_order  \n",
      "9               i need help canceling purchase  cancel_order  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Remove placeholders like {{Order Number}}, {{Invoice Number}}, etc.\n",
    "df_clean['instruction_clean'] = df_clean['instruction'].apply(\n",
    "    lambda x: re.sub(r'\\{\\{.*?\\}\\}', '', x)\n",
    ")\n",
    "\n",
    "# Convert to lowercase\n",
    "df_clean['instruction_clean'] = df_clean['instruction_clean'].str.lower()\n",
    "\n",
    "# Remove extra whitespaces\n",
    "df_clean['instruction_clean'] = df_clean['instruction_clean'].str.strip()\n",
    "df_clean['instruction_clean'] = df_clean['instruction_clean'].apply(\n",
    "    lambda x: re.sub(r'\\s+', ' ', x)\n",
    ")\n",
    "\n",
    "# Remove any rows with empty instructions after cleaning\n",
    "df_clean = df_clean[df_clean['instruction_clean'].str.len() > 0]\n",
    "\n",
    "print(\"Dataset shape after cleaning:\", df_clean.shape)\n",
    "print(\"\\nSample cleaned instructions:\")\n",
    "print(df_clean[['instruction', 'instruction_clean', 'intent']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b426df",
   "metadata": {},
   "source": [
    "## Intent Classification Model using NLP + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fe2d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = ['scikit-learn', 'nltk']\n",
    "for package in packages:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "941ec778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c3a3dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 21497\n",
      "Testing set size: 5375\n",
      "\n",
      "Class distribution in training set:\n",
      "intent\n",
      "check_invoice               800\n",
      "contact_customer_service    800\n",
      "switch_account              800\n",
      "complaint                   800\n",
      "edit_account                800\n",
      "payment_issue               799\n",
      "delivery_period             799\n",
      "contact_human_agent         799\n",
      "get_invoice                 799\n",
      "check_payment_methods       799\n",
      "registration_problems       799\n",
      "newsletter_subscription     799\n",
      "track_refund                798\n",
      "cancel_order                798\n",
      "place_order                 798\n",
      "check_refund_policy         798\n",
      "get_refund                  798\n",
      "review                      798\n",
      "set_up_shipping_address     798\n",
      "change_order                798\n",
      "create_account              798\n",
      "track_order                 796\n",
      "delivery_options            796\n",
      "delete_account              796\n",
      "recover_password            796\n",
      "change_shipping_address     778\n",
      "check_cancellation_fee      760\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and labels\n",
    "X = df_clean['instruction_clean']\n",
    "y = df_clean['intent']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed00d8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorization completed!\n",
      "Training data shape: (21497, 5000)\n",
      "Testing data shape: (5375, 5000)\n",
      "Number of features: 5000\n"
     ]
    }
   ],
   "source": [
    "# Create TF-IDF Vectorizer\n",
    "# TF-IDF converts text to numerical features\n",
    "# - removes english stopwords (common words like 'the', 'is', 'and')\n",
    "# - uses unigrams and bigrams (1 and 2 word phrases)\n",
    "# - limits to top 5000 features\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english',\n",
    "    min_df=2,\n",
    "    max_df=0.9\n",
    ")\n",
    "\n",
    "# Transform training and testing data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF Vectorization completed!\")\n",
    "print(f\"Training data shape: {X_train_tfidf.shape}\")\n",
    "print(f\"Testing data shape: {X_test_tfidf.shape}\")\n",
    "print(f\"Number of features: {len(tfidf_vectorizer.get_feature_names_out())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbad7dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression model...\n",
      "Model training completed!\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression model\n",
    "print(\"Training Logistic Regression model...\")\n",
    "\n",
    "logistic_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    solver='lbfgs'\n",
    ")\n",
    "\n",
    "logistic_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Model training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f23165",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b36855f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9769 (97.69%)\n",
      "Training Accuracy: 0.9860 (98.60%)\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = logistic_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Get training accuracy\n",
    "y_train_pred = logistic_model.predict(X_train_tfidf)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "069522bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intent\n",
       "check_invoice               1000\n",
       "complaint                   1000\n",
       "contact_customer_service    1000\n",
       "edit_account                1000\n",
       "switch_account              1000\n",
       "check_payment_methods        999\n",
       "contact_human_agent          999\n",
       "delivery_period              999\n",
       "get_invoice                  999\n",
       "newsletter_subscription      999\n",
       "payment_issue                999\n",
       "registration_problems        999\n",
       "cancel_order                 998\n",
       "place_order                  998\n",
       "track_refund                 998\n",
       "change_order                 997\n",
       "check_refund_policy          997\n",
       "create_account               997\n",
       "get_refund                   997\n",
       "review                       997\n",
       "set_up_shipping_address      997\n",
       "delete_account               995\n",
       "delivery_options             995\n",
       "recover_password             995\n",
       "track_order                  995\n",
       "change_shipping_address      973\n",
       "check_cancellation_fee       950\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['intent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab293396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "================================================================================\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "            cancel_order       0.99      0.98      0.99       200\n",
      "            change_order       0.96      0.94      0.95       199\n",
      " change_shipping_address       0.99      1.00      0.99       195\n",
      "  check_cancellation_fee       1.00      1.00      1.00       190\n",
      "           check_invoice       0.82      0.86      0.84       200\n",
      "   check_payment_methods       1.00      1.00      1.00       200\n",
      "     check_refund_policy       1.00      0.99      1.00       199\n",
      "               complaint       1.00      1.00      1.00       200\n",
      "contact_customer_service       1.00      0.98      0.99       200\n",
      "     contact_human_agent       0.99      0.99      0.99       200\n",
      "          create_account       0.99      0.97      0.98       199\n",
      "          delete_account       0.94      0.99      0.97       199\n",
      "        delivery_options       0.92      1.00      0.96       199\n",
      "         delivery_period       1.00      0.99      1.00       200\n",
      "            edit_account       0.98      1.00      0.99       200\n",
      "             get_invoice       0.85      0.82      0.84       200\n",
      "              get_refund       0.99      1.00      1.00       199\n",
      " newsletter_subscription       1.00      0.99      0.99       200\n",
      "           payment_issue       1.00      0.98      0.99       200\n",
      "             place_order       0.99      0.97      0.98       200\n",
      "        recover_password       0.99      1.00      1.00       199\n",
      "   registration_problems       0.98      0.99      0.99       200\n",
      "                  review       1.00      1.00      1.00       199\n",
      " set_up_shipping_address       1.00      0.99      0.99       199\n",
      "          switch_account       0.99      0.96      0.98       200\n",
      "             track_order       1.00      0.94      0.97       199\n",
      "            track_refund       1.00      1.00      1.00       200\n",
      "\n",
      "                accuracy                           0.98      5375\n",
      "               macro avg       0.98      0.98      0.98      5375\n",
      "            weighted avg       0.98      0.98      0.98      5375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_test, y_pred, target_names=logistic_model.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9c3822",
   "metadata": {},
   "source": [
    "## Test the Model with Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "300b3f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_intent(text):\n",
    "    \"\"\"\n",
    "    Predict the intent of a given text\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to classify\n",
    "        \n",
    "    Returns:\n",
    "        Predicted intent and confidence scores\n",
    "    \"\"\"\n",
    "    # Clean the text (same as training data)\n",
    "    text_clean = re.sub(r'\\{\\{.*?\\}\\}', '', text)\n",
    "    text_clean = text_clean.lower().strip()\n",
    "    text_clean = re.sub(r'\\s+', ' ', text_clean)\n",
    "    \n",
    "    # Transform using TF-IDF\n",
    "    text_tfidf = tfidf_vectorizer.transform([text_clean])\n",
    "    \n",
    "    # Predict\n",
    "    prediction = logistic_model.predict(text_tfidf)[0]\n",
    "    probabilities = logistic_model.predict_proba(text_tfidf)[0]\n",
    "    \n",
    "    # Get top 3 predictions with probabilities\n",
    "    top_indices = probabilities.argsort()[-3:][::-1]\n",
    "    top_intents = [(logistic_model.classes_[i], probabilities[i]) for i in top_indices]\n",
    "    \n",
    "    print(f\"Input: {text}\")\n",
    "    print(f\"Cleaned: {text_clean}\")\n",
    "    print(f\"\\nPredicted Intent: {prediction}\")\n",
    "    print(f\"Confidence: {max(probabilities):.4f}\")\n",
    "    print(f\"\\nTop 3 predictions:\")\n",
    "    for intent, prob in top_intents:\n",
    "        print(f\"  - {intent}: {prob:.4f}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31ef754e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Intent Classifier with Sample Queries\n",
      "================================================================================\n",
      "Input: I want to cancel my order\n",
      "Cleaned: i want to cancel my order\n",
      "\n",
      "Predicted Intent: cancel_order\n",
      "Confidence: 0.9439\n",
      "\n",
      "Top 3 predictions:\n",
      "  - cancel_order: 0.9439\n",
      "  - delivery_options: 0.0091\n",
      "  - delete_account: 0.0077\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Input: How can I track my package?\n",
      "Cleaned: how can i track my package?\n",
      "\n",
      "Predicted Intent: track_refund\n",
      "Confidence: 0.3129\n",
      "\n",
      "Top 3 predictions:\n",
      "  - track_refund: 0.3129\n",
      "  - track_order: 0.1774\n",
      "  - delivery_period: 0.0959\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Input: I need help setting up my account\n",
      "Cleaned: i need help setting up my account\n",
      "\n",
      "Predicted Intent: delete_account\n",
      "Confidence: 0.1686\n",
      "\n",
      "Top 3 predictions:\n",
      "  - delete_account: 0.1686\n",
      "  - switch_account: 0.1349\n",
      "  - create_account: 0.1220\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Input: What are the delivery options available?\n",
      "Cleaned: what are the delivery options available?\n",
      "\n",
      "Predicted Intent: delivery_options\n",
      "Confidence: 0.9393\n",
      "\n",
      "Top 3 predictions:\n",
      "  - delivery_options: 0.9393\n",
      "  - check_payment_methods: 0.0156\n",
      "  - set_up_shipping_address: 0.0043\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Input: I forgot my password, please help\n",
      "Cleaned: i forgot my password, please help\n",
      "\n",
      "Predicted Intent: recover_password\n",
      "Confidence: 0.4773\n",
      "\n",
      "Top 3 predictions:\n",
      "  - recover_password: 0.4773\n",
      "  - get_invoice: 0.0390\n",
      "  - change_order: 0.0375\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Input: Can you send me my invoice?\n",
      "Cleaned: can you send me my invoice?\n",
      "\n",
      "Predicted Intent: get_invoice\n",
      "Confidence: 0.8222\n",
      "\n",
      "Top 3 predictions:\n",
      "  - get_invoice: 0.8222\n",
      "  - check_invoice: 0.0459\n",
      "  - review: 0.0242\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Input: I want to change my shipping address\n",
      "Cleaned: i want to change my shipping address\n",
      "\n",
      "Predicted Intent: change_shipping_address\n",
      "Confidence: 0.8903\n",
      "\n",
      "Top 3 predictions:\n",
      "  - change_shipping_address: 0.8903\n",
      "  - set_up_shipping_address: 0.0598\n",
      "  - switch_account: 0.0100\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Input: How do I get a refund?\n",
      "Cleaned: how do i get a refund?\n",
      "\n",
      "Predicted Intent: get_refund\n",
      "Confidence: 0.6638\n",
      "\n",
      "Top 3 predictions:\n",
      "  - get_refund: 0.6638\n",
      "  - track_refund: 0.2740\n",
      "  - check_refund_policy: 0.0364\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with sample customer queries\n",
    "test_queries = [\n",
    "    \"I want to cancel my order\",\n",
    "    \"How can I track my package?\",\n",
    "    \"I need help setting up my account\",\n",
    "    \"What are the delivery options available?\",\n",
    "    \"I forgot my password, please help\",\n",
    "    \"Can you send me my invoice?\",\n",
    "    \"I want to change my shipping address\",\n",
    "    \"How do I get a refund?\"\n",
    "]\n",
    "\n",
    "print(\"Testing Intent Classifier with Sample Queries\")\n",
    "print(\"=\" * 80)\n",
    "for query in test_queries:\n",
    "    predict_intent(query)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192c11f6",
   "metadata": {},
   "source": [
    "## Model Summary\n",
    "\n",
    "### Key Achievements:\n",
    "1. **Data Cleaning**: Successfully cleaned 26,872 customer support queries by:\n",
    "   - Removing placeholders ({{Order Number}}, etc.)\n",
    "   - Converting to lowercase\n",
    "   - Removing extra whitespaces\n",
    "\n",
    "2. **Feature Engineering**: Used TF-IDF Vectorization with:\n",
    "   - 5000 features\n",
    "   - Unigrams and bigrams (1-2 word phrases)\n",
    "   - English stopwords removed\n",
    "\n",
    "3. **Model Performance**:\n",
    "   - **Test Accuracy: 97.69%**\n",
    "   - **Training Accuracy: 98.60%**\n",
    "   - Successfully classifies 27 different customer intents\n",
    "\n",
    "4. **Model Components**:\n",
    "   - **NLP Technique**: TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "   - **Classifier**: Logistic Regression\n",
    "   - **Dataset**: Bitext Customer Support Dataset (26,872 examples)\n",
    "\n",
    "### Use Case:\n",
    "This model can automatically classify customer support queries into 27 different intents, enabling:\n",
    "- Automated routing to appropriate support teams\n",
    "- Quick response suggestions\n",
    "- Better customer service analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504a01fe",
   "metadata": {},
   "source": [
    "## Save Model and Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdd48113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TF-IDF Vectorizer saved to: ../models\\tfidf_vectorizer.pkl\n",
      "✓ Logistic Regression Model saved to: ../models\\logistic_regression_model.pkl\n",
      "\n",
      "Both models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Create a models directory if it doesn't exist\n",
    "models_dir = '../models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "vectorizer_path = os.path.join(models_dir, 'tfidf_vectorizer.pkl')\n",
    "with open(vectorizer_path, 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "print(f\"✓ TF-IDF Vectorizer saved to: {vectorizer_path}\")\n",
    "\n",
    "# Save the Logistic Regression model\n",
    "model_path = os.path.join(models_dir, 'logistic_regression_model.pkl')\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(logistic_model, f)\n",
    "print(f\"✓ Logistic Regression Model saved to: {model_path}\")\n",
    "\n",
    "print(\"\\nBoth models saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3351891c",
   "metadata": {},
   "source": [
    "### Load Saved Models (for future use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a80df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: How to load the saved models later\n",
    "# Uncomment and run this code when you want to load the models\n",
    "\n",
    "# import pickle\n",
    "# \n",
    "# # Load TF-IDF Vectorizer\n",
    "# with open('../models/tfidf_vectorizer.pkl', 'rb') as f:\n",
    "#     loaded_vectorizer = pickle.load(f)\n",
    "# \n",
    "# # Load Logistic Regression Model\n",
    "# with open('../models/logistic_regression_model.pkl', 'rb') as f:\n",
    "#     loaded_model = pickle.load(f)\n",
    "# \n",
    "# print(\"Models loaded successfully!\")\n",
    "# \n",
    "# # Test with a sample query\n",
    "# test_text = \"I want to cancel my order\"\n",
    "# test_text_clean = test_text.lower().strip()\n",
    "# test_tfidf = loaded_vectorizer.transform([test_text_clean])\n",
    "# prediction = loaded_model.predict(test_tfidf)[0]\n",
    "# print(f\"Prediction: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
